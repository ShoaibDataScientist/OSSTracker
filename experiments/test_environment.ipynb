{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test file to check if the environment is properly configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries needed for data preprocessing successfully imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd as xl\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import pickle, re, json, os, datetime, time\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "print('All libraries needed for data preprocessing successfully imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries needed for knowledge type prediction successfully imported.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from operator import itemgetter\n",
    "from functools import partial, update_wrapper\n",
    "from openpyxl import load_workbook\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.pipeline import FeatureUnion, _fit_transform_one, _transform_one\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from imblearn.pipeline import Pipeline as Imb_Pipeline\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, accuracy_score, make_scorer, confusion_matrix\n",
    "\n",
    "## Ignore warnings\n",
    "import warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "print('All libraries needed for knowledge type prediction successfully imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the output of the top 2 cells say:\n",
    "\n",
    "`All libraries needed for data preprocessing successfully imported.`\n",
    "\n",
    "### and\n",
    "\n",
    "`All libraries needed for knowledge type prediction successfully imported.`\n",
    "\n",
    "### Congratulations! Your environment is set up and sufficient to perform the experiments in this work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's take a look at the data provided in this repository\n",
    "\n",
    "*all_data.pkl* contains the result of execution of the cells in *preprocess_data.ipynb*. It contains the text content of each of the sentences in the corpus, its annotated information type, as well as metadata information with respect to *Participants*, *Length*, *Structure*, *Temporal* and *Code* aspects as described in the paper describing this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of corpus: 4330\n"
     ]
    }
   ],
   "source": [
    "## Read the data from the pickle file\n",
    "all_data = pd.read_pickle('../data/all_data.pkl')\n",
    "print(\"Size of corpus: \"+str(len(all_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique knowledge types: 13\n",
      "[   'Action on Issue',\n",
      "    'Bug Reproduction',\n",
      "    'Contribution and Commitment',\n",
      "    'Expected Behaviour',\n",
      "    'Investigation and Exploration',\n",
      "    'Motivation',\n",
      "    'Observed Bug Behaviour',\n",
      "    'Potential New Issues and Requests',\n",
      "    'Social Conversation',\n",
      "    'Solution Discussion',\n",
      "    'Task Progress',\n",
      "    'Usage',\n",
      "    'Workarounds']\n"
     ]
    }
   ],
   "source": [
    "## Get the set of all unique knowledge types in the corpus\n",
    "\n",
    "knowledge_types = list(set(all_data['Code']))\n",
    "print(\"Number of unique knowledge types: \"+str(len(knowledge_types)))\n",
    "knowledge_types.sort()\n",
    "\n",
    "pp.pprint(knowledge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences from tensorflowissues: 2100\n",
      "Number of sentences from scikit-learnissues: 1401\n",
      "Number of sentences from spaCyissues: 829\n"
     ]
    }
   ],
   "source": [
    "projects = ['tensorflow','scikit-learn','spaCy']\n",
    "for proj in projects:\n",
    "    print(\"Number of sentences from \"+proj+\"issues: \"+str(len(all_data[all_data.Document.str.contains(proj)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Text Content</th>\n",
       "      <th>Code</th>\n",
       "      <th>Full Length</th>\n",
       "      <th>len</th>\n",
       "      <th>tloc</th>\n",
       "      <th>cloc</th>\n",
       "      <th>tpos1</th>\n",
       "      <th>tpos2</th>\n",
       "      <th>clen</th>\n",
       "      <th>tlen</th>\n",
       "      <th>ppau</th>\n",
       "      <th>npau</th>\n",
       "      <th>aa</th>\n",
       "      <th>begauth</th>\n",
       "      <th>has_code</th>\n",
       "      <th>first_turn</th>\n",
       "      <th>last_turn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 37_tensorflow.doc</td>\n",
       "      <td>Node.js (JavaScript) Wrapper API</td>\n",
       "      <td>Expected Behaviour</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00229358</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0555556</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000464767</td>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 37_tensorflow.doc</td>\n",
       "      <td>Because JavaScript is Awesome</td>\n",
       "      <td>Motivation</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00458716</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0555556</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000464767</td>\n",
       "      <td>NONE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 37_tensorflow.doc</td>\n",
       "      <td>+1!</td>\n",
       "      <td>Social Conversation</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00688073</td>\n",
       "      <td>2.58297e-05</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0138889</td>\n",
       "      <td>0.000464767</td>\n",
       "      <td>0.000916033</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Document                      Text Content                 Code  \\\n",
       "0  1 37_tensorflow.doc  Node.js (JavaScript) Wrapper API   Expected Behaviour   \n",
       "1  1 37_tensorflow.doc     Because JavaScript is Awesome           Motivation   \n",
       "2  1 37_tensorflow.doc                               +1!  Social Conversation   \n",
       "\n",
       "  Full Length len tloc        cloc        tpos1     tpos2 clen       tlen  \\\n",
       "0          32  32  0.5  0.00229358            0  1.000000    1  0.0555556   \n",
       "1          29  29    1  0.00458716            0  1.000000    1  0.0555556   \n",
       "2           3   3    1  0.00688073  2.58297e-05  0.999974    1  0.0138889   \n",
       "\n",
       "          ppau         npau    aa begauth has_code first_turn last_turn  \n",
       "0            0  0.000464767  NONE    True    False       True     False  \n",
       "1            0  0.000464767  NONE    True    False       True     False  \n",
       "2  0.000464767  0.000916033  NONE   False    False      False     False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.iloc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now do a transformation on the data:\n",
    "\n",
    "1. Drop *Full Length*\n",
    "2. Convert *begauth* which contains values `True` and `False` to One Hot Encoding\n",
    "3. Convert the time-based feature *tpos2* to a numeric field.\n",
    "\n",
    "We'll store this converted data into a file called *just_testing.pkl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "## Drop \"Full Length\"\n",
    "just_testing_data = all_data[['Document','Text Content','Code','len','tloc','cloc','tpos1','tpos2','clen','tlen','ppau','npau','aa','begauth','has_code','first_turn','last_turn']]\n",
    "\n",
    "# Convert \"begauth\" which contains values `True` and `False` to One Hot Encoding\n",
    "just_testing_data = pd.get_dummies(just_testing_data,columns = ['begauth'])\n",
    "\n",
    "# Convert the time-based feature \"tpos2\" to a numeric field.\n",
    "just_testing_data.tpos2.astype(int)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Text Content</th>\n",
       "      <th>Code</th>\n",
       "      <th>len</th>\n",
       "      <th>tloc</th>\n",
       "      <th>cloc</th>\n",
       "      <th>tpos1</th>\n",
       "      <th>tpos2</th>\n",
       "      <th>clen</th>\n",
       "      <th>tlen</th>\n",
       "      <th>ppau</th>\n",
       "      <th>npau</th>\n",
       "      <th>aa</th>\n",
       "      <th>has_code</th>\n",
       "      <th>first_turn</th>\n",
       "      <th>last_turn</th>\n",
       "      <th>begauth_False</th>\n",
       "      <th>begauth_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 37_tensorflow.doc</td>\n",
       "      <td>Node.js (JavaScript) Wrapper API</td>\n",
       "      <td>Expected Behaviour</td>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00229358</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0555556</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000464767</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 37_tensorflow.doc</td>\n",
       "      <td>Because JavaScript is Awesome</td>\n",
       "      <td>Motivation</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00458716</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0555556</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000464767</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 37_tensorflow.doc</td>\n",
       "      <td>+1!</td>\n",
       "      <td>Social Conversation</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00688073</td>\n",
       "      <td>2.58297e-05</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0138889</td>\n",
       "      <td>0.000464767</td>\n",
       "      <td>0.000916033</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Document                      Text Content                 Code  \\\n",
       "0  1 37_tensorflow.doc  Node.js (JavaScript) Wrapper API   Expected Behaviour   \n",
       "1  1 37_tensorflow.doc     Because JavaScript is Awesome           Motivation   \n",
       "2  1 37_tensorflow.doc                               +1!  Social Conversation   \n",
       "\n",
       "  len tloc        cloc        tpos1     tpos2 clen       tlen         ppau  \\\n",
       "0  32  0.5  0.00229358            0  1.000000    1  0.0555556            0   \n",
       "1  29    1  0.00458716            0  1.000000    1  0.0555556            0   \n",
       "2   3    1  0.00688073  2.58297e-05  0.999974    1  0.0138889  0.000464767   \n",
       "\n",
       "          npau    aa has_code first_turn last_turn  begauth_False  \\\n",
       "0  0.000464767  NONE    False       True     False              0   \n",
       "1  0.000464767  NONE    False       True     False              0   \n",
       "2  0.000916033  NONE    False      False     False              1   \n",
       "\n",
       "   begauth_True  \n",
       "0             1  \n",
       "1             1  \n",
       "2             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_testing_data.iloc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the field *Full Length* no longer exists and the field *begauth* has now been changed to *begauth_False* and *begauth_True*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save transformed features in pickle file\n",
    "just_testing_data.to_pickle('../data/just_testing.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting knowledge type of a sentence - a basic method\n",
    "\n",
    "#### Building a Logistic Regression model to predict the knowledge type of a sentence based on textual content:\n",
    "- The set of sentences are split into 2 parts - 80% are used for training and 20% used for testing the prediction model.\n",
    "- The text content of the sentences is transformed into a vector format of the frequencies of words.\n",
    "- Logistic Regression is used to train the model on the training data.\n",
    "- The model then predicts on the test data and the precision, recall and f1-score of the predicted data with respect to the actual annotated knowledge type is displayed in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Action on Issue       0.67      0.29      0.40         7\n",
      "                 Bug Reproduction       0.46      0.33      0.38        55\n",
      "      Contribution and Commitment       0.50      0.24      0.32        17\n",
      "               Expected Behaviour       0.33      0.06      0.10        18\n",
      "    Investigation and Exploration       0.34      0.23      0.28        65\n",
      "                       Motivation       0.42      0.18      0.25        61\n",
      "           Observed Bug Behaviour       0.42      0.16      0.23        31\n",
      "Potential New Issues and Requests       0.40      0.20      0.27        49\n",
      "              Social Conversation       0.56      0.82      0.67       172\n",
      "              Solution Discussion       0.56      0.74      0.64       291\n",
      "                    Task Progress       0.33      0.19      0.24        21\n",
      "                            Usage       0.48      0.45      0.47        64\n",
      "                      Workarounds       1.00      0.07      0.12        15\n",
      "\n",
      "                        micro avg       0.53      0.53      0.53       866\n",
      "                        macro avg       0.50      0.30      0.34       866\n",
      "                     weighted avg       0.51      0.53      0.49       866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = all_data['Text Content']\n",
    "y = all_data['Code']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10, shuffle=True)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_tf = vectorizer.fit_transform(X_train)\n",
    "X_test_tf = vectorizer.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "model = clf.fit(X_train_tf, y_train)\n",
    "y_pred = clf.predict(X_test_tf)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results may seem okay, but this is just one scenario of a train-test split. There is no guarantee that the classifier will perform the same way if the split was made differently so that there were a different set of training and testing sentences. But that's okay. This is just to make sure your environment works.\n",
    "\n",
    "### You can now continue to the main experiments in this paper. The _**README**_ will give you a better understanding of this repository's structure and how to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
